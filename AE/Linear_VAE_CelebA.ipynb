{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cd5d672-911c-4a94-bafe-6d6f3332048f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Device (GPU or CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7539f80-cb05-4e45-bbb5-9b38b4b3e1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torch.utils.data import sampler\n",
    "batch_size = 256\n",
    "lr = 1e-4\n",
    "n_epoch = 100\n",
    "train_loader = DataLoader(\n",
    "    datasets.ImageFolder('/datasets/CelebA-stargan', transforms.Compose([\n",
    "        transforms.CenterCrop((128,128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))  # 用均值和方差归一化图片\n",
    "    ])),\n",
    "    batch_size=batch_size, shuffle=False,\n",
    "    num_workers=32,pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c174446e-e7e8-4e15-be27-13fa963a303e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE_autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE_autoencoder, self).__init__()\n",
    "        \n",
    "        #define encoder & decoder\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(16384 * 3, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 20),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(12, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048, 16384 * 3),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.fc_m = nn.Linear(20,12)\n",
    "        self.fc_sigma = nn.Linear(20,12)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        code = x.view(x.size(0), -1)\n",
    "        code = self.encoder(code)\n",
    "        \n",
    "        # m, sigma\n",
    "        m = self.fc_m(code)\n",
    "        sigma = self.fc_sigma(code)\n",
    "        \n",
    "        # define e\n",
    "        e = torch.randn_like(sigma)\n",
    "        \n",
    "        #define c\n",
    "        c = torch.exp(sigma) * e + m\n",
    "        output = self.decoder(c)\n",
    "#         output = output.view(x.size(0), 3, 128, 128)\n",
    "        \n",
    "        return output, m, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd20ae1c-308a-402e-b7ae-d5712f28db15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE_autoencoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=49152, out_features=2048, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (9): ReLU()\n",
       "    (10): Linear(in_features=128, out_features=20, bias=True)\n",
       "    (11): ReLU()\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=12, out_features=20, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=20, out_features=128, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Linear(in_features=512, out_features=1024, bias=True)\n",
       "    (9): ReLU()\n",
       "    (10): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "    (11): ReLU()\n",
       "    (12): Linear(in_features=2048, out_features=49152, bias=True)\n",
       "    (13): Sigmoid()\n",
       "  )\n",
       "  (fc_m): Linear(in_features=20, out_features=12, bias=True)\n",
       "  (fc_sigma): Linear(in_features=20, out_features=12, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = VAE_autoencoder().to(device)\n",
    "criterion = nn.MSELoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d5c4e3-5462-4992-aa3d-4e36c19f4033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch is: 1, Loss is:0.7193\n",
      "epoch is: 2, Loss is:0.7178\n",
      "epoch is: 3, Loss is:0.7158\n",
      "epoch is: 4, Loss is:0.7129\n",
      "epoch is: 5, Loss is:0.7083\n",
      "epoch is: 6, Loss is:0.6950\n",
      "epoch is: 7, Loss is:0.6247\n",
      "epoch is: 8, Loss is:0.4233\n",
      "epoch is: 9, Loss is:0.3491\n",
      "epoch is: 10, Loss is:0.3416\n",
      "epoch is: 11, Loss is:0.3547\n",
      "epoch is: 12, Loss is:0.3652\n",
      "epoch is: 13, Loss is:0.3702\n",
      "epoch is: 14, Loss is:0.3689\n",
      "epoch is: 15, Loss is:0.3631\n",
      "epoch is: 16, Loss is:0.3554\n",
      "epoch is: 17, Loss is:0.3480\n",
      "epoch is: 18, Loss is:0.3415\n",
      "epoch is: 19, Loss is:0.3358\n",
      "epoch is: 20, Loss is:0.3318\n",
      "epoch is: 21, Loss is:0.3285\n",
      "epoch is: 22, Loss is:0.3252\n",
      "epoch is: 23, Loss is:0.3240\n",
      "epoch is: 24, Loss is:0.3206\n",
      "epoch is: 25, Loss is:0.3204\n",
      "epoch is: 26, Loss is:0.3161\n",
      "epoch is: 27, Loss is:0.3170\n",
      "epoch is: 28, Loss is:0.3134\n",
      "epoch is: 29, Loss is:0.3139\n",
      "epoch is: 30, Loss is:0.3119\n",
      "epoch is: 31, Loss is:0.3111\n",
      "epoch is: 32, Loss is:0.3100\n",
      "epoch is: 33, Loss is:0.3085\n",
      "epoch is: 34, Loss is:0.3076\n",
      "epoch is: 35, Loss is:0.3066\n",
      "epoch is: 36, Loss is:0.3057\n",
      "epoch is: 37, Loss is:0.3040\n",
      "epoch is: 38, Loss is:0.3030\n",
      "epoch is: 39, Loss is:0.3027\n",
      "epoch is: 40, Loss is:0.3025\n",
      "epoch is: 41, Loss is:0.3014\n",
      "epoch is: 42, Loss is:0.3015\n",
      "epoch is: 43, Loss is:0.3006\n",
      "epoch is: 44, Loss is:0.2997\n",
      "epoch is: 45, Loss is:0.3006\n",
      "epoch is: 46, Loss is:0.2987\n",
      "epoch is: 47, Loss is:0.2991\n",
      "epoch is: 48, Loss is:0.2984\n",
      "epoch is: 49, Loss is:0.2980\n",
      "epoch is: 50, Loss is:0.2979\n",
      "epoch is: 51, Loss is:0.2973\n",
      "epoch is: 52, Loss is:0.2980\n",
      "epoch is: 53, Loss is:0.2973\n",
      "epoch is: 54, Loss is:0.2971\n",
      "epoch is: 55, Loss is:0.2967\n",
      "epoch is: 56, Loss is:0.2963\n",
      "epoch is: 57, Loss is:0.2968\n",
      "epoch is: 58, Loss is:0.2964\n",
      "epoch is: 59, Loss is:0.2964\n",
      "epoch is: 60, Loss is:0.2967\n",
      "epoch is: 61, Loss is:0.2959\n",
      "epoch is: 62, Loss is:0.2960\n",
      "epoch is: 63, Loss is:0.2959\n",
      "epoch is: 64, Loss is:0.2961\n",
      "epoch is: 65, Loss is:0.2957\n",
      "epoch is: 66, Loss is:0.2956\n",
      "epoch is: 67, Loss is:0.2953\n",
      "epoch is: 68, Loss is:0.2953\n",
      "epoch is: 69, Loss is:0.2953\n",
      "epoch is: 70, Loss is:0.2953\n",
      "epoch is: 71, Loss is:0.2952\n",
      "epoch is: 72, Loss is:0.2950\n",
      "epoch is: 73, Loss is:0.2947\n",
      "epoch is: 74, Loss is:0.2945\n",
      "epoch is: 75, Loss is:0.2948\n",
      "epoch is: 76, Loss is:0.2946\n",
      "epoch is: 77, Loss is:0.2947\n",
      "epoch is: 78, Loss is:0.2955\n",
      "epoch is: 79, Loss is:0.2946\n",
      "epoch is: 80, Loss is:0.2944\n",
      "epoch is: 81, Loss is:0.2947\n",
      "epoch is: 82, Loss is:0.2950\n",
      "epoch is: 83, Loss is:0.2948\n",
      "epoch is: 84, Loss is:0.2955\n",
      "epoch is: 85, Loss is:0.2949\n",
      "epoch is: 86, Loss is:0.2944\n",
      "epoch is: 87, Loss is:0.2943\n",
      "epoch is: 88, Loss is:0.2943\n",
      "epoch is: 89, Loss is:0.2944\n",
      "epoch is: 90, Loss is:0.2942\n",
      "epoch is: 91, Loss is:0.2942\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for epoch in range(n_epoch):\n",
    "     \n",
    "    #trianing Net\n",
    "    for batch_idx, (real_image, _) in enumerate(train_loader):\n",
    "        \n",
    "        real_image = real_image.view(real_image.shape[0], -1).to(device)\n",
    "        fake_image, m, sigma = model(real_image)\n",
    "        \n",
    "        KLD = 0.5 * torch.sum(\n",
    "            torch.pow(m, 2) +\n",
    "            torch.pow(sigma, 2) -\n",
    "            torch.log(1e-8 + torch.pow(sigma, 2)) - 1\n",
    "        ) / (real_image.size(0)*128*128)\n",
    "        KLD = KLD.to(device)\n",
    "        \n",
    "        MSE = criterion(fake_image, real_image)\n",
    "        \n",
    "        loss = KLD + MSE\n",
    "        \n",
    "        # updata parametor\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "    print('epoch is: {}, Loss is:{:.4f}'.format(epoch+1, loss.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54e61a6-af85-4bf4-b671-5faa4cf245bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.figure().gca()\n",
    "ax.plot(losses)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train'])\n",
    "plt.title('Loss over training epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be76b5b6-89ae-43b8-a4f7-c16d154b0831",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cae281f-703b-4caf-99d4-164e3a41832f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e1e190-12f0-495d-8e10-d7506864413b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
